{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P_OhOwiBF0La"
   },
   "outputs": [],
   "source": [
    "! [ -e /content ] && pip install -Uqq mrl-pypi  # download MRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ea0KaBIraKGe"
   },
   "outputs": [],
   "source": [
    "!pip install pandas==1.3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogZjhihhF0Lb"
   },
   "source": [
    "# Design de Peptídeo Antimicrobiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qwxwEPNF0Ld"
   },
   "source": [
    "## Design de Peptídeo Antimicrobiano\n",
    "\n",
    "Esse é o código das etapas para design de novos peptídeos antimicrobianos, utilizando a biblioteca MRL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg9brcauF0Le"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.chem import *\n",
    "from mrl.templates.all import *\n",
    "\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.layers import *\n",
    "from mrl.dataloaders import *\n",
    "from mrl.g_models.all import *\n",
    "from mrl.vocab import *\n",
    "from mrl.policy_gradient import *\n",
    "from mrl.train.all import *\n",
    "from mrl.model_zoo import *\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from google.colab import files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xKTwI89F0Lf"
   },
   "outputs": [],
   "source": [
    "os.makedirs('untracked_files', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j62JUkt-F0Lg"
   },
   "source": [
    "## Dados\n",
    "\n",
    "A base de dados foi atualizada e filtrada do banco de dados GRAMPA (WITTEN; WITTEN, 2019).  para conter somente peptídeos antimicrobianos com tamanho entre 5-15 peptídeos e atividade antimicrobiana menor que 32 uM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3LKwjIEF0Lh"
   },
   "outputs": [],
   "source": [
    "download_files()\n",
    "df = pd.read_csv('../dados/k_pneumonia_peptides.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4INFKk8F0Lh"
   },
   "outputs": [],
   "source": [
    "df = df[[\"name\", 'sequence', \"dataset\", \"label\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHXbL_2yF0Ll"
   },
   "source": [
    "## Função de Pontuação\n",
    "\n",
    "Foi utilizada um encoder RNC com uma MLP head para predizer uma classificação binária para o valor de atividade antimicrobiana. Essa foi a função de pontuação para contar a recompensa dos peptídeos gerados nas etapas a frente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHniNcYbF0Ll"
   },
   "outputs": [],
   "source": [
    "train_df = df[df.dataset=='train']\n",
    "valid_df = df[df.dataset=='valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfX1Ir56F0Lm"
   },
   "outputs": [],
   "source": [
    "aa_vocab = CharacterVocab(AMINO_ACID_VOCAB)\n",
    "\n",
    "amp_ds = Text_Prediction_Dataset(train_df.sequence.values, train_df.label.values, aa_vocab)\n",
    "test_ds = Text_Prediction_Dataset(valid_df.sequence.values, valid_df.label.values, aa_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POKB6egdF0Lm"
   },
   "source": [
    "Esse é modelo que foi utilizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGMH262UF0Lm"
   },
   "outputs": [],
   "source": [
    "class Predictive_CNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_vocab,\n",
    "                 d_embedding,\n",
    "                 d_latent,\n",
    "                 filters,\n",
    "                 kernel_sizes,\n",
    "                 strides,\n",
    "                 dropouts,\n",
    "                 mlp_dims,\n",
    "                 mlp_drops,\n",
    "                 d_out\n",
    "                ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_encoder = Conv_Encoder(\n",
    "                                        d_vocab,\n",
    "                                        d_embedding,\n",
    "                                        d_latent,\n",
    "                                        filters,\n",
    "                                        kernel_sizes,\n",
    "                                        strides,\n",
    "                                        dropouts,\n",
    "                                    )\n",
    "\n",
    "        self.mlp_head = MLP(\n",
    "                            d_latent,\n",
    "                            mlp_dims,\n",
    "                            d_out,\n",
    "                            mlp_drops\n",
    "                            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.conv_encoder(x)\n",
    "        out = self.mlp_head(encoded)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYWDh0BWF0Lm"
   },
   "outputs": [],
   "source": [
    "d_vocab = len(aa_vocab.itos)\n",
    "d_embedding = 256\n",
    "d_latent = 512\n",
    "filters = [128, 256]\n",
    "kernel_sizes = [5, 5]\n",
    "strides = [1, 1]\n",
    "dropouts = [0.2, 0.2, 0.2]\n",
    "mlp_dims = [512, 256, 128]\n",
    "mlp_drops = [0.2, 0.2, 0.2]\n",
    "d_out = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZQSu4i_ncQD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "all_preds = []\n",
    "all_targs = []\n",
    "\n",
    "k_folds = 5\n",
    "\n",
    "sequences = np.array(df.sequence.values)\n",
    "labels = np.array(df.label.values)\n",
    "\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (train_idxs, valid_idxs) in enumerate(kf.split(sequences)):\n",
    "    print(f\"Fold {fold + 1}/{k_folds}\")\n",
    "\n",
    "    train_ds = Text_Prediction_Dataset(\n",
    "        sequences[train_idxs],\n",
    "        labels[train_idxs],\n",
    "        aa_vocab\n",
    "    )\n",
    "    valid_ds = Text_Prediction_Dataset(\n",
    "        sequences[valid_idxs],\n",
    "        labels[valid_idxs],\n",
    "        aa_vocab\n",
    "    )\n",
    "\n",
    "    amp_model = Predictive_CNN(\n",
    "        d_vocab,\n",
    "        d_embedding,\n",
    "        d_latent,\n",
    "        filters,\n",
    "        kernel_sizes,\n",
    "        strides,\n",
    "        dropouts,\n",
    "        mlp_dims,\n",
    "        mlp_drops,\n",
    "        d_out\n",
    "    )\n",
    "\n",
    "    r_agent = PredictiveAgent(\n",
    "        amp_model,\n",
    "        BinaryCrossEntropy(),\n",
    "        train_ds,\n",
    "        opt_kwargs={'lr': 1e-3}\n",
    "    )\n",
    "\n",
    "    r_agent.train_supervised(bs=32, epochs=30, lr=1e-3)\n",
    "\n",
    "    valid_preds = r_agent.predict_dataset(valid_ds, detach=True)\n",
    "    valid_labels = torch.tensor(labels[valid_idxs], dtype=torch.float32)\n",
    "\n",
    "    valid_preds_bin = (valid_preds > 0.5).float()\n",
    "    accuracy = (valid_preds_bin == valid_labels).sum().item() / len(valid_labels)\n",
    "\n",
    "    print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
    "    fold_metrics.append(accuracy)\n",
    "\n",
    "    valid_dl = valid_ds.dataloader(256, shuffle=False)\n",
    "    fold_preds = []\n",
    "    fold_targs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dl:\n",
    "            batch = to_device(batch)\n",
    "            x, y = batch\n",
    "            pred = r_agent.model(x)\n",
    "            fold_preds.append(pred.detach().cpu())\n",
    "            fold_targs.append(y.detach().cpu())\n",
    "\n",
    "    all_preds.append(torch.cat(fold_preds))\n",
    "    all_targs.append(torch.cat(fold_targs))\n",
    "\n",
    "mean_accuracy = np.mean(fold_metrics)\n",
    "std_accuracy = np.std(fold_metrics)\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "print(f\"Standard Deviation: {std_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1fGsdPor-sR"
   },
   "outputs": [],
   "source": [
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_targs = torch.cat(all_targs).numpy()\n",
    "\n",
    "fpr, tpr, _ = roc_curve(all_targs, torch.tensor(all_preds).sigmoid().squeeze().numpy())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='Curva ROC (área = %0.4f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de falsos positivos')\n",
    "plt.ylabel('Taxa de verdadeiros positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cxs7qse2F0Lo"
   },
   "outputs": [],
   "source": [
    "r_agent.save_weights('untracked_files/amp_predictor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKChZU4aF0Lp"
   },
   "source": [
    "## O Espaço químico\n",
    "\n",
    "Nessa etapa, foi desenvolvido o espaço químico. Aqui foi decidido quais peptídeos deveriam ser inclusos e quais seriam removidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGxKYG54h4TK"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from rdkit import Chem\n",
    "\n",
    "moon_fleming_scale = {\n",
    "    \"A\": -1.57,\n",
    "    \"R\": 2.14,\n",
    "    \"N\": 1.91,\n",
    "    \"D\": 1.38,\n",
    "    \"C\": -1.08,\n",
    "    \"Q\": 1.44,\n",
    "    \"E\": 0.07,\n",
    "    \"G\": 0.15,\n",
    "    \"H\": 3.19,\n",
    "    \"I\": -3.12,\n",
    "    \"L\": -3.32,\n",
    "    \"K\": 3.82,\n",
    "    \"M\": -2.33,\n",
    "    \"F\": -3.77,\n",
    "    \"P\": -3.09,\n",
    "    \"S\": 0.26,\n",
    "    \"T\": 0.21,\n",
    "    \"W\": -1.95,\n",
    "    \"Y\": -2.66,\n",
    "    \"V\": -2.34,\n",
    "}\n",
    "\n",
    "def get_hydrophobic_values(mol: str) -> list[float]:\n",
    "    \"\"\"\n",
    "    Transforma cada aminoácido no valor hidrofóbico correspondente da escala.\n",
    "\n",
    "    :param mol: A sequência do peptídeo\n",
    "    :return hvalues: A sequência do peptídeo convertida para valores da escala\n",
    "    \"\"\"\n",
    "    hvalues = []\n",
    "\n",
    "    for aa in mol:\n",
    "        sc_hydrophobicity = moon_fleming_scale.get(aa, None)\n",
    "        if sc_hydrophobicity is None:\n",
    "            raise KeyError(\"Aminoácido não definido na escala: {}\".format(aa))\n",
    "        hvalues.append(sc_hydrophobicity)\n",
    "    return hvalues\n",
    "\n",
    "\n",
    "def calculate_moment(mol: str) -> float:\n",
    "    \"\"\"\n",
    "    Calcula o momento dipolar hidrofóbico a partir de uma matriz de valores\n",
    "    de hidrofobicidade. Fórmula definida por Eisenberg, 1982 (Nature).\n",
    "    Retorna o momento médio (normalizado pelo comprimento da sequência).\n",
    "\n",
    "    uH = sqrt(sum(Hi cos(i*d))**2 + sum(Hi sin(i*d))**2),\n",
    "    onde i é o índice do aminoácido e d (delta) é um valor angular em\n",
    "    graus (100 para alfa-hélice, 180 para folha beta).\n",
    "\n",
    "    :param mol: A sequência do peptídeo\n",
    "    :return hm: O valor do momento hidrofóbico\n",
    "    \"\"\"\n",
    "    mol1 = Chem.MolToSequence(mol)\n",
    "    angle = 100\n",
    "    sum_cos, sum_sin = 0.0, 0.0\n",
    "    hvalues = get_hydrophobic_values(mol1)\n",
    "    for i, hv in enumerate(hvalues):\n",
    "        rad_inc = ((i * angle) * math.pi) / 180.0\n",
    "        sum_cos += hv * math.cos(rad_inc)\n",
    "        sum_sin += hv * math.sin(rad_inc)\n",
    "    return math.sqrt(sum_cos**2 + sum_sin**2) / len(hvalues)\n",
    "\n",
    "\n",
    "def calculate_hydrophobicity(mol: str) -> float:\n",
    "    \"\"\"\n",
    "    Calcula o valor da hidrofobicidade para cada aminoácido na sequência.\n",
    "\n",
    "    :param mol: A sequência do peptídeo\n",
    "    :return h: O valor da hidrofobicidade do peptídeo\n",
    "    \"\"\"\n",
    "    mol1 = Chem.MolToSequence(mol)\n",
    "    hvalues = get_hydrophobic_values(mol1)\n",
    "    hydrophobicity = sum(hvalues) / len(hvalues)\n",
    "    return hydrophobicity\n",
    "\n",
    "\n",
    "class HydrophobicityFilter(PropertyFilter):\n",
    "    def __init__(self, min_val, max_val, score=None, name=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Filtro que avalia a hidrofobicidade do peptídeo.\n",
    "\n",
    "        :param min_val: Valor mínimo permitido de hidrofobicidade\n",
    "        :param max_val: Valor máximo permitido de hidrofobicidade\n",
    "        :param score: Pontuação atribuída ao filtro\n",
    "        :param name: Nome do filtro\n",
    "        :param kwargs: Argumentos adicionais\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            calculate_hydrophobicity,\n",
    "            min_val=min_val,\n",
    "            max_val=max_val,\n",
    "            score=score,\n",
    "            name=name,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "class HydrophobicityMomentFilter(PropertyFilter):\n",
    "    def __init__(self, min_val, max_val, score=None, name=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Filtro que avalia o momento hidrofóbico do peptídeo.\n",
    "\n",
    "        :param min_val: Valor mínimo permitido do momento hidrofóbico\n",
    "        :param max_val: Valor máximo permitido do momento hidrofóbico\n",
    "        :param score: Pontuação atribuída ao filtro\n",
    "        :param name: Nome do filtro\n",
    "        :param kwargs: Argumentos adicionais\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            calculate_moment,\n",
    "            min_val=min_val,\n",
    "            max_val=max_val,\n",
    "            score=score,\n",
    "            name=name,\n",
    "            **kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-99yYerW_jw"
   },
   "outputs": [],
   "source": [
    "class CombinedCharacterCountFilter(Filter):\n",
    "    '''\n",
    "    CombinedCharacterCountFilter - valida um `Mol` com base na contagem combinada de caracteres específicos\n",
    "\n",
    "    Entradas:\n",
    "    - `char_groups list[list[str]]`: lista de grupos de caracteres a serem contados como uma única entidade\n",
    "    - `min_val Optional[float, int]`: valor mínimo para a contagem\n",
    "    - `max_val Optional[float, int]`: valor máximo para a contagem\n",
    "    - `per_length bool`: se True, as contagens são normalizadas pelo comprimento da string\n",
    "    - `score [None, int, float, ScoreFunction]`: veja `Filter.set_score`\n",
    "    - `name Optional[str]`: nome do filtro usado na representação (`repr`)\n",
    "    - `fail_score [float, int]`: usado em `Filter.set_score` se `score_function` for (int, float)\n",
    "    - `mode str['smile', 'protein', 'dna', 'rna']`: determina como as entradas são convertidas em objetos Mol\n",
    "    '''\n",
    "    def __init__(self, char_groups, min_val=None, max_val=None, per_length=False,\n",
    "                 score=None, name=None, fail_score=0., mode='smile'):\n",
    "        if name is None:\n",
    "            name = f\"Filtro de Contagem Combinada de Caracteres\"\n",
    "\n",
    "        super().__init__(score, name, fail_score=fail_score, mode=mode)\n",
    "\n",
    "        self.char_groups = char_groups\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "        self.per_length = per_length\n",
    "\n",
    "    def property_function(self, mol):\n",
    "        return self.to_string(mol)\n",
    "\n",
    "    def criteria_function(self, property_output):\n",
    "        total_count = sum(property_output.count(char) for group in self.char_groups for char in group)\n",
    "\n",
    "        if self.per_length:\n",
    "            total_count /= len(property_output)  # Normaliza pela extensão da string, se necessário\n",
    "\n",
    "        meets_min = (total_count >= self.min_val) if self.min_val is not None else True\n",
    "        meets_max = (total_count <= self.max_val) if self.max_val is not None else True\n",
    "\n",
    "        return meets_min and meets_max\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.name} ({self.min_val}, {self.max_val})'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nyp3rp0TZGnG"
   },
   "outputs": [],
   "source": [
    "aa_vocab = CharacterVocab(AMINO_ACID_VOCAB)\n",
    "\n",
    "template = Template([\n",
    "    ValidityFilter(),\n",
    "    CombinedCharacterCountFilter(\n",
    "        char_groups=[['R', 'K']],\n",
    "        min_val=5,\n",
    "        max_val=None,\n",
    "        per_length=False,\n",
    "        mode='protein'\n",
    "    ),\n",
    "\n",
    "    HydrophobicityFilter(min_val=0, max_val=1, mode='protein'),\n",
    "    HydrophobicityMomentFilter(min_val=0, max_val=1, mode='protein'),\n",
    "    CharacterCountFilter(['D'], min_val=0, max_val=0, per_length=True, mode='protein'),\n",
    "    CharacterCountFilter(['E'], min_val=0, max_val=0, per_length=True, mode='protein'),\n",
    "    CharacterCountFilter(['C'], min_val=0, max_val=0, per_length=True, mode='protein'),\n",
    "    CharacterCountFilter(aa_vocab.itos[4:], min_val=0, max_val=0.4, per_length=True, mode='protein'),\n",
    "    PropertyFilter(molwt, min_val=800, max_val=3000)\n",
    "], [], fail_score=-10., log=False, use_lookup=False, mode='protein')\n",
    "\n",
    "template_cb = TemplateCallback(template, prefilter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14CDrdyNF0Lq"
   },
   "source": [
    "## Carregar Modelo\n",
    "\n",
    "O modelo `LSTM_LM_Small_Swissprot` foi carregado para base do modelo gerativo. Ele é um modelo básico treinado na base de dados Swissprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2wrxu0qF0Lq"
   },
   "outputs": [],
   "source": [
    "agent = LSTM_LM_Small_Swissprot(drop_scale=0.3, opt_kwargs={'lr':1e-4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxfS6HBVF0Lr"
   },
   "source": [
    "## Fine-Tune o modelo\n",
    "\n",
    "O modelo pré-treinado que foi carregado é muito generalizado e pode produzir uma grande diversidade de estruturas. Nós precisamos especificamente de peptídeos antimicrobianos, então realizamos um finetuning na base de dados AMPlify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "be3c5jb0ih1j"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dados/Amplify.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v63lIIR1F0Lr"
   },
   "outputs": [],
   "source": [
    "agent.update_dataset_from_inputs(df[df.label==1].sequence.values)\n",
    "agent.train_supervised(32, 8, 5e-5)\n",
    "agent.base_to_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sf5XhQyF0Lr"
   },
   "outputs": [],
   "source": [
    "agent.save_weights('untracked_files/finetuned_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVIcS1KKF0Lr"
   },
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "Essa é a parte de Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yH5emNYAF0Lr"
   },
   "source": [
    "### Perda\n",
    "\n",
    "Foi usado `PPO` como a política de perda de gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BWvutTHsF0Ls"
   },
   "outputs": [],
   "source": [
    "pg = PPO(0.99,\n",
    "        0.5,\n",
    "        lam=0.95,\n",
    "        v_coef=0.5,\n",
    "        cliprange=0.3,\n",
    "        v_cliprange=0.3,\n",
    "        ent_coef=0.01,\n",
    "        kl_target=0.03,\n",
    "        kl_horizon=3000,\n",
    "        scale_rewards=True)\n",
    "\n",
    "loss = PolicyLoss(pg, 'PPO',\n",
    "                   value_head=ValueHead(256),\n",
    "                   v_update_iter=2,\n",
    "                   vopt_kwargs={'lr':1e-3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwXALbyhF0Ls"
   },
   "source": [
    "### Recompensa\n",
    "\n",
    "O agente de recompensa treinado anteriormente foi passado para um callback.  \n",
    "\n",
    "Como o modelo é de classificação, foi necessário definir qual valor seria utilizado na função de pontuação. Duas abordagens foram consideradas:  \n",
    "\n",
    "1. **Saída escalada pela função sigmoide** – Gera muitas amostras com pontuação próxima de `0.999`, dificultando a diferenciação entre as melhores.  \n",
    "2. **Saída do logit bruto** – Permite melhor distinção das amostras no topo, mas pode gerar valores extremos.  \n",
    "\n",
    "A abordagem escolhida foi a saída do logit bruto, com valores limitados ao intervalo `[-10, 10]`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kKLFNHHF0Ls"
   },
   "outputs": [],
   "source": [
    "d_vocab = len(aa_vocab.itos)\n",
    "d_embedding = 256\n",
    "d_latent = 512\n",
    "filters = [128, 256]\n",
    "kernel_sizes = [5, 5]\n",
    "strides = [1, 1]\n",
    "dropouts = [0.2, 0.2, 0.2]\n",
    "mlp_dims = [512, 256, 128]\n",
    "mlp_drops = [0.2, 0.2, 0.2]\n",
    "d_out = 1\n",
    "\n",
    "\n",
    "reward_model = Predictive_CNN(\n",
    "                    d_vocab,\n",
    "                    d_embedding,\n",
    "                    d_latent,\n",
    "                    filters,\n",
    "                    kernel_sizes,\n",
    "                    strides,\n",
    "                    dropouts,\n",
    "                    mlp_dims,\n",
    "                    mlp_drops,\n",
    "                    d_out\n",
    "                )\n",
    "\n",
    "\n",
    "r_ds = Text_Prediction_Dataset(['M'], [0.], aa_vocab)\n",
    "\n",
    "r_agent = PredictiveAgent(reward_model, BinaryCrossEntropy(), r_ds, opt_kwargs={'lr':1e-3})\n",
    "\n",
    "r_agent.load_weights('untracked_files/amp_predictor.pt')\n",
    "# r_agent.load_state_dict(model_from_url('amp_predictor.pt')) # optional - load exact weights\n",
    "\n",
    "reward_model.eval();\n",
    "\n",
    "freeze(reward_model)\n",
    "\n",
    "class ClippedModelReward():\n",
    "    def __init__(self, agent, minclip, maxclip):\n",
    "        self.agent = agent\n",
    "        self.minclip = minclip\n",
    "        self.maxclip = maxclip\n",
    "\n",
    "    def __call__(self, sequences):\n",
    "        preds = self.agent.predict_data(sequences)\n",
    "        preds = torch.clamp(preds, self.minclip, self.maxclip)\n",
    "        return preds\n",
    "\n",
    "reward_function = Reward(ClippedModelReward(r_agent, -10, 10), weight=1)\n",
    "\n",
    "amp_reward = RewardCallback(reward_function, 'amp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjOqCXXoF0Ls"
   },
   "source": [
    "### Métrica de Estabilidade  \n",
    "\n",
    "Modelos de linguagem baseados em transformadores têm sido utilizados para aprendizado não supervisionado de estruturas de proteínas. Estudos recentes indicam uma relação entre a probabilidade logarítmica da sequência de uma proteína, gerada por um modelo generativo, e sua estabilidade.  \n",
    "\n",
    "A probabilidade logarítmica fornecida por um modelo transformer pré-treinado foi utilizada como um indicativo de estabilidade. Incluir essa métrica como função de recompensa auxilia na geração de peptídeos mais realistas.  \n",
    "\n",
    "Para essa etapa, foi utilizado o modelo ESM de grande escala, com **630M parâmetros**. Esse recurso melhora a qualidade dos resultados, mas aumenta significativamente o tempo de treinamento.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJSmiFEcF0Ls"
   },
   "outputs": [],
   "source": [
    "! pip install fair-esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVWEJVIhF0Lt"
   },
   "outputs": [],
   "source": [
    "import esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2CFroweF0Lt"
   },
   "outputs": [],
   "source": [
    "protein_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JiwAesHuF0Lt"
   },
   "outputs": [],
   "source": [
    "class PeptideStability():\n",
    "    def __init__(self, model, alphabet, batch_converter):\n",
    "        self.model = model\n",
    "        to_device(self.model)\n",
    "        self.alphabet = alphabet\n",
    "        self.batch_converter = batch_converter\n",
    "\n",
    "    def __call__(self, samples):\n",
    "\n",
    "        data = [\n",
    "            (f'protein{i}', samples[i]) for i in range(len(samples))\n",
    "        ]\n",
    "\n",
    "        batch_labels, batch_strs, batch_tokens = self.batch_converter(data)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            results = self.model(to_device(batch_tokens))\n",
    "\n",
    "        lps = F.log_softmax(results['logits'], -1)\n",
    "\n",
    "        mean_lps = lps.gather(2, to_device(batch_tokens).unsqueeze(-1)).squeeze(-1).mean(-1)\n",
    "\n",
    "        return mean_lps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaNR-bsRF0Lt"
   },
   "outputs": [],
   "source": [
    "ps = PeptideStability(protein_model, alphabet, batch_converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5JGAy-wF0Lu"
   },
   "outputs": [],
   "source": [
    "stability_reward = Reward(ps, weight=0.1, bs=300)\n",
    "stability_cb = RewardCallback(stability_reward, name='stability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-iTo5hAF0Lu"
   },
   "outputs": [],
   "source": [
    "stability_reward(df.sequence.values[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWvWAjI3F0Lu"
   },
   "source": [
    "### Amostradores  \n",
    "\n",
    "Foram utilizados os seguintes amostradores:  \n",
    "- **`sampler1 ModelSampler`**: amostra do modelo principal, adicionando 1000 compostos ao buffer a cada atualização e extraindo 40% das amostras de cada lote diretamente do modelo.  \n",
    "- **`sampler2 ModelSampler`**: amostra do modelo base, sem amostragem dinâmica em cada lote.  \n",
    "- **`sampler3 LogSampler`**: seleciona amostras de alta pontuação do registro (`log`).  \n",
    "- **`sampler4 TokenSwapSampler`**: utiliza a técnica de troca de tokens (`combi-chem`) para gerar novas amostras a partir das de maior pontuação.  \n",
    "- **`sampler5 DatasetSampler`**: adiciona uma pequena quantidade de compostos ativos conhecidos em cada atualização do buffer, garantindo alinhamento com o comprimento gerado (75 aminoácidos).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Th3aBIOIF0Lu"
   },
   "outputs": [],
   "source": [
    "gen_bs = 1500\n",
    "\n",
    "sampler1 = ModelSampler(agent.vocab, agent.model, 'live', 1000, 0., gen_bs)\n",
    "sampler2 = ModelSampler(agent.vocab, agent.base_model, 'base', 1000, 0., gen_bs)\n",
    "sampler3 = LogSampler('samples', 'rewards', 10, 98, 200)\n",
    "sampler4 = TokenSwapSampler('samples', 'rewards', 10, 98, 200, aa_vocab, 0.2)\n",
    "sampler5 = DatasetSampler(df[(df.label==1) & (df.sequence.map(lambda x: len(x)<=75))].sequence.values,\n",
    "                          'data', buffer_size=4)\n",
    "\n",
    "samplers = [sampler1, sampler2, sampler3, sampler4, sampler5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ABivkvsF0Lv"
   },
   "source": [
    "### Callbacks  \n",
    "\n",
    "- **`SupervisedCB`**: realiza treinamento supervisionado com os 3% melhores exemplos a cada 400 lotes.  \n",
    "- **`MaxCallback`**: imprime a recompensa máxima de cada lote.  \n",
    "- **`PercentileCallback`**: imprime a pontuação do percentil 90 a cada lote.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXOle-bmF0Lv"
   },
   "outputs": [],
   "source": [
    "supervised_cb = SupervisedCB(agent, 20, 0.5, 98, 1e-4, 64)\n",
    "live_max = MaxCallback('rewards', 'live')\n",
    "live_p90 = PercentileCallback('rewards', 'live', 90)\n",
    "\n",
    "cbs = [supervised_cb, live_p90, live_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nxl8UbbF0Lv"
   },
   "source": [
    "## Ambiente e treinamento\n",
    "\n",
    "Aqui foi organizado o ambiente e rodado o treinamento em fim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUuyOMRQF0Lw"
   },
   "outputs": [],
   "source": [
    "env = Environment(agent, template_cb, samplers=samplers, rewards=[amp_reward, stability_cb], losses=[loss],\n",
    "                 cbs=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUMIXZ1XF0Lw"
   },
   "outputs": [],
   "source": [
    "set_global_pool(min(12, os.cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkNhO0HkF0Lw"
   },
   "outputs": [],
   "source": [
    "env.fit(128, 75, 300, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4mMc8Q0F0Lw"
   },
   "outputs": [],
   "source": [
    "env.log.plot_metrics()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1S5IrE6fucXRF2w6afT1RsXx0KOa6MqJZ",
     "timestamp": 1731513037120
    },
    {
     "file_id": "1Ov6nRUdSL0NKMi-JjrKPytDDsq5N8lsp",
     "timestamp": 1725386113226
    },
    {
     "file_id": "https://github.com/DarkMatterAI/mrl/blob/master/nbs/tutorials/tutorials.proteins.amp.ipynb",
     "timestamp": 1712602982864
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
